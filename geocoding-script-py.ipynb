{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import dependencies\nimport pandas as pd\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom bs4 import BeautifulSoup\nfrom googlemaps import Client as GoogleMaps\nimport googlemaps\nimport gmaps\n\n\n# Set up Chrome options\nchrome_options = Options()\nchrome_options.add_argument('--no-sandbox')\nchrome_options.add_argument('--headless')\nchrome_options.add_argument('--disable-gpu')\nchrome_options.add_argument('--disable-dev-shm-usage')\nchrome_options.add_argument(\"--window-size=1920,1080\")\n\n\n# Path to chromedriver executable\nchromedriver_path = '/usr/local/bin/chromedriver'\n\n\n# Set up Selenium driver\ndriver = webdriver.Chrome(executable_path=chromedriver_path, options=chrome_options)\n\n\n# Load the website\nurl = 'https://internet.safaricom.co.ke/5g-wireless/coverage'\ndriver.get(url)\n\n\n# Wait for the table to be loaded\nwait = WebDriverWait(driver, 10)\ntable = wait.until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"5G-coverage\"]/div[2]/div/div/div/div[2]/table')))\n\n\n# Parse the HTML content using BeautifulSoup\nsoup = BeautifulSoup(table.get_attribute('outerHTML'), 'html.parser')\n\n# Extract the table data using Pandas\ndfs = pd.read_html(str(soup))\ndf = dfs[0]\n\n#drop the County and Area columns\ndf = df.drop(['County', 'Area'] , axis=1)\n\n# Separate the entries into rows\ndf = df['Place/Estate'].str.split(', ', expand=True).stack().reset_index(level=1, drop=True).to_frame('Place/Estate')\n\n# Reset the index of the DataFrame\ndf = df.reset_index(drop=True)\n\n#drop duplicate entries\ndf=df.drop_duplicates(keep='last')\n\n# This is where we will need the API key\ngmaps = googlemaps.Client(key='YOUR API KEY')\n\n\naddress = df.iloc[:, -1:].copy()  # Selecting the last column of the DataFrame and making a copy\naddress.loc[:, 'long'] = \"\"  # Setting empty values in the 'long' column\naddress.loc[:, 'lat'] = \"\"  # Setting empty values in the 'lat' column\n\n# Iterate over the indices of the DataFrame 'address'\nfor x in range(len(address)):\n    # Perform geocoding for the address at index 'x'\n    geocode_result = gmaps.geocode(address.loc[x, 'Place/Estate'])\n    \n    # Check if a geocoding result is obtained\n    if geocode_result:\n        # Update the 'lat' column of 'addresses2' with the latitude value from the geocoding result\n        address.at[x, 'lat'] = geocode_result[0]['geometry']['location']['lat']\n        \n        # Update the 'long' column of 'addresses2' with the longitude value from the geocoding result\n        address.at[x, 'long'] = geocode_result[0]['geometry']['location']['lng']\n    else:\n        # Set the 'lat' column to None if no geocoding result is obtained\n        address.at[x, 'lat'] = None\n        \n        # Set the 'long' column to None if no geocoding result is obtained\n        address.at[x, 'long'] = None\n        \n# Data to add\ndata = [\n    ('Karen', -1.31294888109111, 36.68288232510159),\n    ('Utawala', -1.3334768985469356, 36.67656180973276),\n    ('Ushirika', -1.2724597960984732, 36.84438912079378),\n    ('Zimmerman', -1.2089039495782525, 36.898427146205144),\n    ('Junction', -1.2985895292447076, 36.76320215391012),\n    ('Lower Riat Estate', -0.053248757434864, 34.739411198093606),\n    ('Mamboleo', -0.05796940333424934, 34.78539405944491),\n    ('St Aloys Ojola', -0.05982833865938444, 34.65003218274472),\n    ('Kirigiti', -1.1713665430229177, 36.841963772341195)\n]\n\n# Iterate over the data items\nfor item in data:\n    # Unpack the item into place, longitude, and latitude variables\n    place, longitude, latitude = item\n    \n    # Update the 'long' and 'lat' columns of 'address' where the 'Place/Estate' matches the 'place' value\n    address.loc[address['Place/Estate'] == place, ['lat', 'long']] = latitude, longitude\n    \n    \n    \n    \n        ","metadata":{},"execution_count":null,"outputs":[]}]}